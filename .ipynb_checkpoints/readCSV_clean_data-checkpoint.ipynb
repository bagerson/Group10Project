{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store filepath in a variable\n",
    "file_one = \"Resources/DJIA.csv\"\n",
    "file_two = \"Resources/NASDAQ100.csv\"\n",
    "file_three = \"Resources/SP500.csv\"\n",
    "file_four = \"Resources/HPI_master.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read our Data files with the pandas library and create DF\n",
    "DJIA_df = pd.read_csv(file_one)\n",
    "\n",
    "# Separate out the month and year cols\n",
    "DJIA_df['Year'] = pd.DatetimeIndex(DJIA_df['DATE']).year\n",
    "DJIA_df['Month'] = pd.DatetimeIndex(DJIA_df['DATE']).month\n",
    "\n",
    "# Filter everything before 2009 out (Which just happens to be the year here)\n",
    "DJIA_df = DJIA_df[DJIA_df.Year >= 2009]\n",
    "# We also need to filter the other end of the data because stock data ends at Jan 2019, HPI data ends at March 2019. It's easy to just filter by year so we can lose the months.\n",
    "#Trying to filter out just the last two months may be harder but would give us Jan 2019 data when plotting.\n",
    "DJIA_df = DJIA_df[DJIA_df.Year <= 2018]\n",
    "\n",
    "\n",
    "#Drop junk rows with VALUE of \".\"\n",
    "DJIA_df.drop(DJIA_df[DJIA_df.VALUE == \".\"].index, inplace=True)\n",
    "\n",
    "#Convert the rest to floats\n",
    "DJIA_df['VALUE'] = DJIA_df['VALUE'].astype(float)\n",
    "\n",
    "#Group by Year, Month and average the 30 days\n",
    "DJIA_df_mean = DJIA_df.groupby(['Year','Month'])['VALUE'].mean().pct_change()\n",
    "\n",
    "#Multiply it by 100 it's now in percent.\n",
    "DJIA_df_mean = DJIA_df_mean * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAS_df = pd.read_csv(file_two)\n",
    "\n",
    "NAS_df['Year'] = pd.DatetimeIndex(NAS_df['DATE']).year\n",
    "NAS_df['Month'] = pd.DatetimeIndex(NAS_df['DATE']).month\n",
    "\n",
    "NAS_df = NAS_df[NAS_df.Year >= 2009]\n",
    "NAS_df = NAS_df[NAS_df.Year <= 2018]\n",
    "\n",
    "NAS_df.drop(NAS_df[NAS_df.VALUE == \".\"].index, inplace=True)\n",
    "\n",
    "NAS_df['VALUE'] = NAS_df['VALUE'].astype(float)\n",
    "\n",
    "NAS_df_mean = NAS_df.groupby(['Year','Month'])['VALUE'].mean().pct_change()\n",
    "\n",
    "NAS_df_mean = NAS_df_mean * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_df = pd.read_csv(file_three)\n",
    "\n",
    "SP500_df = pd.read_csv(file_two)\n",
    "\n",
    "SP500_df['year'] = pd.DatetimeIndex(SP500_df['DATE']).year\n",
    "SP500_df['month'] = pd.DatetimeIndex(SP500_df['DATE']).month\n",
    "\n",
    "SP500_df = SP500_df[SP500_df.year >= 2009]\n",
    "SP500_df = SP500_df[SP500_df.year <= 2018]\n",
    "\n",
    "SP500_df.drop(SP500_df[SP500_df.VALUE == \".\"].index, inplace=True)\n",
    "\n",
    "SP500_df['VALUE'] = SP500_df['VALUE'].astype(float)\n",
    "\n",
    "SP500_df_mean = SP500_df.groupby(['year','month'])['VALUE'].mean().pct_change()\n",
    "\n",
    "SP500_df_mean = SP500_df_mean * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding index_sa vs index_nsa\n",
    "\n",
    "Q: For those HPIs that are seasonally adjusted, what approach is used in performing the seasonal adjustment?\n",
    "\n",
    "A: The Census Bureau's X-12 ARIMA procedure is used, as implemented in the SAS software package. The automated ARIMA model-selection algorithm in X-12 is employed, which searches through a series of seasonality structures and selects the first that satisfies the Ljung-Box test for serial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_df = pd.read_csv(file_four)\n",
    "HPI_df = HPI_df.rename(columns={\"yr\":\"Year\", \"period\":\"Month\"})\n",
    "\n",
    "HPI_df = HPI_df[HPI_df.Year >= 2009]\n",
    "HPI_df = HPI_df[HPI_df.Year <= 2018]\n",
    "HPI_df = HPI_df.drop(HPI_df[HPI_df.frequency == \"quarterly\"].index)\n",
    "\n",
    "#We must mean this as well. There are too many units of data per MonthYear\n",
    "#This means we can also isolate them by region later. \n",
    "HPI_df_mean = HPI_df.groupby([\"Year\", \"Month\"])[\"index_nsa\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to plot the date, we need a column of \"datetime\" object and our current columns don't work\n",
    "\n",
    "#Removes the grouped-by index and turns them into columns, resetting index into 0's \n",
    "SP500_reorganized = SP500_df_mean.reset_index()\n",
    "\n",
    "#datetime requires a day. We don't have a day specified so we'll just assign it to the first of every month.\n",
    "SP500_reorganized[\"day\"] = 1\n",
    "\n",
    "#we create a new column \"Date\" to house the new datetime object.\n",
    "SP500_reorganized[\"Date\"] = pd.to_datetime(SP500_reorganized[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "\n",
    "#This x_axis shoudl work for all plots now.\n",
    "x_axis = SP500_reorganized[\"Date\"]\n",
    "\n",
    "#And we create the Y axis from the values of SP500.\n",
    "SP500_y = SP500_reorganized[\"VALUE\"]\n",
    "\n",
    "plt.plot_date(x_axis, SP500_y,linewidth=1, linestyle=\"--\", marker=\"\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
