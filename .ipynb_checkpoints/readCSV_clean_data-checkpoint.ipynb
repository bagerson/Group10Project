{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store filepath in a variable\n",
    "file_one = \"Resources/DJIA.csv\"\n",
    "file_two = \"Resources/NASDAQ100.csv\"\n",
    "file_three = \"Resources/SP500.csv\"\n",
    "file_four = \"Resources/HPI_master.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read our Data files with the pandas library and create DF\n",
    "DJIA_df = pd.read_csv(file_one)\n",
    "\n",
    "# Separate out the month and year cols\n",
    "DJIA_df['Year'] = pd.DatetimeIndex(DJIA_df['DATE']).year\n",
    "DJIA_df['Month'] = pd.DatetimeIndex(DJIA_df['DATE']).month\n",
    "\n",
    "# Filter everything before 2009 out (Which just happens to be the year here)\n",
    "DJIA_df = DJIA_df[DJIA_df.Year >= 2009]\n",
    "# We also need to filter the other end of the data because stock data ends at Jan 2019, HPI data ends at March 2019. It's easy to just filter by year so we can lose the months.\n",
    "#Trying to filter out just the last two months may be harder but would give us Jan 2019 data when plotting.\n",
    "DJIA_df = DJIA_df[DJIA_df.Year <= 2018]\n",
    "\n",
    "\n",
    "#Drop junk rows with VALUE of \".\"\n",
    "DJIA_df.drop(DJIA_df[DJIA_df.VALUE == \".\"].index, inplace=True)\n",
    "\n",
    "#Convert the rest to floats\n",
    "DJIA_df['VALUE'] = DJIA_df['VALUE'].astype(float)\n",
    "\n",
    "#Group by Year, Month and average the 30 days\n",
    "DJIA_df_mean = DJIA_df.groupby(['Year','Month'])['VALUE'].mean().pct_change()\n",
    "\n",
    "#Multiply it by 100 it's now in percent.\n",
    "DJIA_df_mean = DJIA_df_mean * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAS_df = pd.read_csv(file_two)\n",
    "\n",
    "NAS_df['Year'] = pd.DatetimeIndex(NAS_df['DATE']).year\n",
    "NAS_df['Month'] = pd.DatetimeIndex(NAS_df['DATE']).month\n",
    "\n",
    "NAS_df = NAS_df[NAS_df.Year >= 2009]\n",
    "NAS_df = NAS_df[NAS_df.Year <= 2018]\n",
    "\n",
    "NAS_df.drop(NAS_df[NAS_df.VALUE == \".\"].index, inplace=True)\n",
    "\n",
    "NAS_df['VALUE'] = NAS_df['VALUE'].astype(float)\n",
    "\n",
    "NAS_df_mean = NAS_df.groupby(['Year','Month'])['VALUE'].mean().pct_change()\n",
    "\n",
    "NAS_df_mean = NAS_df_mean * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_df = pd.read_csv(file_three)\n",
    "\n",
    "SP500_df = pd.read_csv(file_two)\n",
    "\n",
    "SP500_df['year'] = pd.DatetimeIndex(SP500_df['DATE']).year\n",
    "SP500_df['month'] = pd.DatetimeIndex(SP500_df['DATE']).month\n",
    "\n",
    "SP500_df = SP500_df[SP500_df.year >= 2009]\n",
    "SP500_df = SP500_df[SP500_df.year <= 2018]\n",
    "\n",
    "SP500_df.drop(SP500_df[SP500_df.VALUE == \".\"].index, inplace=True)\n",
    "\n",
    "SP500_df['VALUE'] = SP500_df['VALUE'].astype(float)\n",
    "\n",
    "SP500_df_mean = SP500_df.groupby(['year','month'])['VALUE'].mean().pct_change()\n",
    "\n",
    "SP500_df_mean = SP500_df_mean * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding index_sa vs index_nsa\n",
    "\n",
    "Q: For those HPIs that are seasonally adjusted, what approach is used in performing the seasonal adjustment?\n",
    "\n",
    "A: The Census Bureau's X-12 ARIMA procedure is used, as implemented in the SAS software package. The automated ARIMA model-selection algorithm in X-12 is employed, which searches through a series of seasonality structures and selects the first that satisfies the Ljung-Box test for serial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_df = pd.read_csv(file_four)\n",
    "HPI_df = HPI_df.rename(columns={\"yr\":\"Year\", \"period\":\"Month\"})\n",
    "\n",
    "HPI_df = HPI_df[HPI_df.Year >= 2009]\n",
    "HPI_df = HPI_df[HPI_df.Year <= 2018]\n",
    "HPI_df = HPI_df.drop(HPI_df[HPI_df.frequency == \"quarterly\"].index)\n",
    "\n",
    "#We must mean this as well. There are too many units of data per MonthYear\n",
    "#This means we can also isolate them by region later. \n",
    "HPI_df_mean = HPI_df.groupby([\"Year\", \"Month\"])[\"index_nsa\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'year': [2015, 2016],\n",
    "                       'month': [2, 3],\n",
    "                       'day': [4, 5]})\n",
    "a = pd.to_datetime(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SP500_df_mean.reset_index()\n",
    "a[\"day\"] = 1\n",
    "a[\"Date\"] = pd.to_datetime(a[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "b = HPI_df_mean.reset_index()\n",
    "\n",
    "x = a[\"Date\"]\n",
    "y = a[\"VALUE\"]\n",
    "\n",
    "# plt.plot_date(a[\"Date\"], a[\"VALUE\"],linewidth=1, linestyle=\"-\", marker=\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-57acebf359c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0mlhs\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# broadcast scale coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DDd->Ddid'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'ddd->ddid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;31m# remove the axis we added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_lstsq\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVD did not converge in Linear Least Squares\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "#To try to create a smooth line as seen here:\n",
    "#https://stackoverflow.com/questions/21367792/how-to-smooth-date-based-data-in-matplotlib\n",
    "x_range = range(len(x))\n",
    "\n",
    "import scipy as sp\n",
    "p = sp.polyfit(x_range, y, deg=50)\n",
    "y_ = sp.polyval(p, x)\n",
    "\n",
    "# plot smoothened data\n",
    "plt.plot(x, y_, color='r', linewidth=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP500_df[\"Month Year\"] = pd.to_datetime(SP500_df['DATE']).dt.to_period('M')?\n",
    "pd.to_datetime?\n",
    "\n",
    "\n",
    "# # x = SP500_df['Month Year'].unique()\n",
    "# # x = list(x)\n",
    "# sp = SP500_df_mean\n",
    "# nas = NAS_df_mean.reset_index()\n",
    "# dj = DJIA_df_mean.reset_index()\n",
    "# x_axis = range(len(x))\n",
    "\n",
    "# x_axis\n",
    "# # plt.plot(x_axis, sp, linewidth=1)\n",
    "# # plt.plot(x_axis, HPI_df_mean, linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
